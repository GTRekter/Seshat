{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìà Metrics Analysis Notebook\n",
    "\n",
    "This notebook analyzes **CPU** and **Memory** resource usage during performance experiments using Fortio and a service mesh (Istio or Linkerd). It reads resource usage data exported in CSV format from the Kubernetes metrics API and generates visualizations per container.\n",
    "\n",
    "## üß™ Experiments Covered\n",
    "\n",
    "1. **01 - HTTP Max Throughput**\n",
    "    - Measures max throughput with default Fortio settings.\n",
    "    - Generates average CPU and memory usage per container.\n",
    "\n",
    "2. **02 - HTTP Constant Throughput**\n",
    "    - Uses constant QPS values: 1, 1000, and 10000.\n",
    "    - Shows how resource usage changes with increasing load.\n",
    "\n",
    "3. **03 - HTTP Payload Variation**\n",
    "    - Fixed QPS (100) with payload sizes: 0, 1000, and 10000 bytes.\n",
    "    - Compares container resource usage with different payload sizes.\n",
    "\n",
    "## üìÅ Expected Input\n",
    "\n",
    "- CSV files under `../results/<experiment>/metrics_<mesh>_<qps>_<payload>_<timestamp>.csv`\n",
    "- Structure:\n",
    "    - `timestamp, namespace, pod, container, cpu(n), memory(Ki)`\n",
    "    - Plus derived fields: `cpu` (as float), `memory` (as float)\n",
    "\n",
    "## üìâ Output\n",
    "\n",
    "- CPU and Memory bar charts per container for each experiment setup.\n",
    "- Output PNGs are saved in:\n",
    "    - `../diagrams/<experiment>/cpu_*.png`\n",
    "    - `../diagrams/<experiment>/memory_*.png`\n",
    "\n",
    "> üìå **Note**: CPU values are shown in nanocores, and memory in Ki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code] Import required libraries\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use a default matplotlib style\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cpu(cpu_str):\n",
    "    \"\"\"\n",
    "    Convert CPU usage from a string with a trailing 'n' (nanocores) \n",
    "    to a float representing millicores (m). (1 millicore = 1e6 nanocores)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nanocores = float(cpu_str.rstrip('n'))\n",
    "        millicores = nanocores / 1e6 \n",
    "        return millicores\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting CPU value '{cpu_str}': {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_memory(mem_str):\n",
    "    \"\"\"\n",
    "    Convert memory usage from a string with a trailing 'Ki' to a float representing megabytes (MB).\n",
    "    (1 MB = 1024 Ki)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ki = float(mem_str.rstrip('Ki'))\n",
    "        mb = ki / 1024.0  # Convert Ki to MB (using 1024 Ki = 1 MB)\n",
    "        return mb\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting memory value '{mem_str}': {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metrics_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file with resource metrics, parses the timestamp, and converts the raw CPU\n",
    "    (nanocores remain unchanged) and memory values (in Ki).\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame with columns:\n",
    "        - timestamp\n",
    "        - namespace\n",
    "        - pod\n",
    "        - container\n",
    "        - cpu(n) (original)\n",
    "        - memory(Ki) (original)\n",
    "        - cpu: numeric CPU in millicore\n",
    "        - memory: numeric memory in MB\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['cpu'] = df['cpu(n)'].apply(convert_cpu)\n",
    "    df['memory'] = df['memory(Ki)'].apply(convert_memory)\n",
    "    return df\n",
    "\n",
    "def extract_mesh_qps_payload(filename):\n",
    "    \"\"\"\n",
    "    Extract mesh, qps, and payload from a filename assumed to be formatted as:\n",
    "      metrics_<mesh>_<qps>_<payload>_<timestamp>.csv\n",
    "    Returns a tuple: (mesh (str), qps (int), payload (int))\n",
    "    \"\"\"\n",
    "    base = os.path.basename(filename)\n",
    "    parts = base.replace(\"metrics_\", \"\").replace(\".csv\", \"\").split(\"_\")\n",
    "    if len(parts) < 3:\n",
    "        return None, None, None\n",
    "    mesh, qps, payload = parts[0], parts[1], parts[2]\n",
    "    return mesh, int(qps), int(payload)\n",
    "\n",
    "def shorten_label(ns, container, max_len=18):\n",
    "    ns_abbr = ns if len(ns) <= max_len else ns[:max_len - 2] + '..'\n",
    "    container_abbr = container if len(container) <= max_len else container[:max_len - 2] + '..'\n",
    "    return f\"{ns_abbr}/{container_abbr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated stats for 01_http_max_throughput:\n",
      "                                                cpu                \\\n",
      "                                               mean        median   \n",
      "namespace              container                                    \n",
      "istio-system           discovery       3.895681e+06  2.777849e+06   \n",
      "                       istio-proxy     2.002482e+08  1.328737e+06   \n",
      "linkerd                destination     1.721479e+06  1.299102e+06   \n",
      "                       identity        3.541669e+05  3.674660e+05   \n",
      "                       linkerd-proxy   5.537078e+05  4.467910e+05   \n",
      "                       policy          5.367995e+05  3.273210e+05   \n",
      "                       proxy-injector  1.240424e+06  2.051620e+05   \n",
      "                       sp-validator    1.914184e+05  1.313040e+05   \n",
      "service-mesh-benchmark istio-proxy     1.513055e+09  1.396071e+09   \n",
      "                       linkerd-proxy   5.402900e+08  4.915040e+08   \n",
      "\n",
      "                                                           memory           \\\n",
      "                                                std          mean   median   \n",
      "namespace              container                                             \n",
      "istio-system           discovery       2.033615e+06  66488.869565  66476.0   \n",
      "                       istio-proxy     3.208684e+08  93446.934783  92648.0   \n",
      "linkerd                destination     4.811407e+05  24489.506494  24480.0   \n",
      "                       identity        3.747471e+04  17489.000000  17488.0   \n",
      "                       linkerd-proxy   1.838656e+05  12686.017544  11872.0   \n",
      "                       policy          2.503183e+05   4951.844156   4940.0   \n",
      "                       proxy-injector  1.078312e+06  24933.000000  24932.0   \n",
      "                       sp-validator    7.172949e+04  20278.421053  20280.0   \n",
      "service-mesh-benchmark istio-proxy     2.361249e+08  63127.854545  63088.0   \n",
      "                       linkerd-proxy   2.990834e+08  22108.895522  21468.0   \n",
      "\n",
      "                                                     \n",
      "                                                std  \n",
      "namespace              container                     \n",
      "istio-system           discovery          37.017732  \n",
      "                       istio-proxy     91861.945386  \n",
      "linkerd                destination        62.218762  \n",
      "                       identity            3.815757  \n",
      "                       linkerd-proxy    1184.513729  \n",
      "                       policy             15.686958  \n",
      "                       proxy-injector      3.815757  \n",
      "                       sp-validator        1.968168  \n",
      "service-mesh-benchmark istio-proxy        83.791500  \n",
      "                       linkerd-proxy    1172.078228  \n",
      "Saved CPU plot to ../diagrams/01_http_max_throughput/cpu_0.png\n",
      "Saved Memory plot to ../diagrams/01_http_max_throughput/memory_0.png\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Process 01_http_max_throughput experiment data and generate aggregated diagrams\n",
    "\n",
    "# Set path to the 01_http_max_throughput experiment directory\n",
    "experiment_dir = os.path.join(\"..\", \"results\", \"01_http_max_throughput\")\n",
    "output_dir = os.path.join(\"..\", \"diagrams\", \"01_http_max_throughput\")\n",
    "csv_files = glob.glob(os.path.join(experiment_dir, 'metrics_*.csv'))\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in:\", experiment_dir)\n",
    "else:\n",
    "    # Load and combine all CSV files\n",
    "    df_list = [load_metrics_csv(file) for file in csv_files]\n",
    "    df_exp = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Drop rows with NaN values in CPU or memory\n",
    "    df_exp = df_exp.dropna(subset=['cpu', 'memory'])\n",
    "\n",
    "    # Aggregate statistics per namespace/container\n",
    "    agg_stats = df_exp.groupby(['namespace', 'container'])[['cpu', 'memory']].agg(['mean', 'median', 'std'])\n",
    "    print(\"Aggregated stats for 01_http_max_throughput:\")\n",
    "    print(agg_stats)\n",
    "\n",
    "    # --- CPU Plot ---\n",
    "    max_cpu = df_exp.groupby(['namespace', 'container'])['cpu'].max()\n",
    "    labels_cpu = [shorten_label(ns, c) for ns, c in max_cpu.index]\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    max_cpu.index = labels_cpu\n",
    "    max_cpu.plot(kind='bar')\n",
    "    plt.ylabel(\"Average CPU Usage (millicore)\")\n",
    "    plt.title(\"01_http_max_throughput: Average CPU Usage per Container\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(output_dir, \"cpu_0.png\")\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(\"Saved CPU plot to\", output_path)\n",
    "\n",
    "    # --- Memory Plot ---\n",
    "    max_memory = df_exp.groupby(['namespace', 'container'])['memory'].max()\n",
    "    labels_mem = [shorten_label(ns, c) for ns, c in max_memory.index]\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    max_memory.index = labels_mem\n",
    "    max_memory.plot(kind='bar', color='tab:orange')\n",
    "    plt.ylabel(\"Average Memory Usage (MB)\")\n",
    "    plt.title(\"01_http_max_throughput: Average Memory Usage per Container\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(output_dir, \"memory_0.png\")\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(\"Saved Memory plot to\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '25Mi': could not convert string to float: '25M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Error converting memory value '14Mi': could not convert string to float: '14M'\n",
      "Saved plot to ../diagrams/02_http_constant_throughput/cpu_1.png\n",
      "Saved plot to ../diagrams/02_http_constant_throughput/memory_1.png\n",
      "Saved plot to ../diagrams/02_http_constant_throughput/cpu_1000.png\n",
      "Saved plot to ../diagrams/02_http_constant_throughput/memory_1000.png\n",
      "Saved plot to ../diagrams/02_http_constant_throughput/cpu_10000.png\n",
      "Saved plot to ../diagrams/02_http_constant_throughput/memory_10000.png\n",
      "Saved plot to ../diagrams/02_http_constant_throughput/cpu_100000.png\n",
      "Saved plot to ../diagrams/02_http_constant_throughput/memory_100000.png\n",
      "Saved plot to ../diagrams/02_http_constant_throughput/cpu_1000000.png\n",
      "Saved plot to ../diagrams/02_http_constant_throughput/memory_1000000.png\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Process 02_http_constant_throughput experiment data with QPS information and save diagrams\n",
    "\n",
    "# Set paths for the results and output diagrams directories\n",
    "results_dir = os.path.join(\"..\", \"results\", \"02_http_constant_throughput\")\n",
    "output_dir  = os.path.join(\"..\", \"diagrams\", \"02_http_constant_throughput\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get all metrics CSV files in the experiment directory\n",
    "csv_files = glob.glob(os.path.join(results_dir, 'metrics_*.csv'))\n",
    "\n",
    "# Label shortening helper\n",
    "def shorten_label(ns, container, max_len=18):\n",
    "    ns_abbr = ns if len(ns) <= max_len else ns[:max_len - 2] + '..'\n",
    "    container_abbr = container if len(container) <= max_len else container[:max_len - 2] + '..'\n",
    "    return f\"{ns_abbr}/{container_abbr}\"\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in:\", results_dir)\n",
    "else:\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        df = load_metrics_csv(file)\n",
    "        # Extract the qps value from the filename using extract_mesh_qps_payload\n",
    "        _, qps, _ = extract_mesh_qps_payload(file)\n",
    "        df['qps'] = qps\n",
    "        df_list.append(df)\n",
    "    df_exp = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Drop rows with missing values to avoid plotting issues\n",
    "    df_exp = df_exp.dropna(subset=['cpu', 'memory', 'qps'])\n",
    "\n",
    "    # Get the unique QPS values present in the data (sorted)\n",
    "    unique_qps = sorted(df_exp['qps'].unique())\n",
    "\n",
    "    # For each QPS value, create and save bar charts for CPU and Memory\n",
    "    for qps_val in unique_qps:\n",
    "        df_qps = df_exp[df_exp['qps'] == qps_val]\n",
    "        for metric, ylabel in [('cpu', \"CPU Usage (millicore)\"), ('memory', \"Memory Usage (MB)\")]:\n",
    "            max_metric = df_qps.groupby(['namespace', 'container'])[metric].max()\n",
    "            labels = [shorten_label(ns, c) for ns, c in max_metric.index]\n",
    "\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            max_metric.index = labels\n",
    "            max_metric.plot(kind='bar')\n",
    "            plt.xlabel(\"Container\")\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.title(f\"02_http_constant_throughput: Average {ylabel} (qps = {qps_val})\")\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "\n",
    "            output_path = os.path.join(output_dir, f\"{metric}_{qps_val}.png\")\n",
    "            plt.savefig(output_path)\n",
    "            plt.close()\n",
    "            print(\"Saved plot to\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to ../diagrams/03_http_payload/cpu_100_10000.png\n",
      "Saved plot to ../diagrams/03_http_payload/memory_100_10000.png\n",
      "Saved plot to ../diagrams/03_http_payload/cpu_100_100000.png\n",
      "Saved plot to ../diagrams/03_http_payload/memory_100_100000.png\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Process 03_http_payload experiment data and plot per container (using payload)\n",
    "\n",
    "# Define directories\n",
    "experiment_dir = os.path.join(\"..\", \"results\", \"03_http_payload\")\n",
    "output_dir  = os.path.join(\"..\", \"diagrams\", \"03_http_payload\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get all metrics CSV files in the experiment directory\n",
    "csv_files = glob.glob(os.path.join(experiment_dir, 'metrics_*.csv'))\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in:\", experiment_dir)\n",
    "else:\n",
    "    # Load each CSV and extract additional parameters (mesh, qps, payload)\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        df = load_metrics_csv(file)\n",
    "        mesh, qps, payload = extract_mesh_qps_payload(file)\n",
    "        df['mesh'] = mesh\n",
    "        df['qps'] = qps\n",
    "        df['payload'] = payload\n",
    "        df_list.append(df)\n",
    "    df_exp = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Identify unique qps and payload values\n",
    "    unique_qps = sorted(df_exp['qps'].dropna().unique())\n",
    "    unique_payload = sorted(df_exp['payload'].dropna().unique())\n",
    "    \n",
    "    # For the purpose of these diagrams, we assume qps is fixed; if not, select an appropriate value.\n",
    "    qps_val = unique_qps[0] if unique_qps else None\n",
    "    \n",
    "    # For each unique payload value, generate separate diagrams for each metric.\n",
    "    for payload_val in unique_payload:\n",
    "        # Filter the DataFrame for the current payload value.\n",
    "        df_subset = df_exp[df_exp['payload'] == payload_val]\n",
    "        for metric, ylabel in [('cpu', \"CPU Usage (millicore)\"), ('memory', \"Memory Usage (MB)\")]:\n",
    "            max_metric = df_subset.groupby(['namespace', 'container'])[metric].max()\n",
    "            labels = [shorten_label(ns, c) for ns, c in max_metric.index]\n",
    "\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            max_metric.index = labels\n",
    "            max_metric.plot(kind='bar')\n",
    "            plt.xlabel(\"Container\")\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.title(f\"03_http_payload: Average {ylabel} (qps = {qps_val}, payload = {payload_val})\")\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"{metric}_{qps_val}_{payload_val}.png\")\n",
    "            plt.savefig(output_path)\n",
    "            plt.close()\n",
    "            print(\"Saved plot to\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to ../diagrams/04_grpc_max_throughput/cpu_0_0.png\n",
      "Saved plot to ../diagrams/04_grpc_max_throughput/memory_0_0.png\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Process 04_grpc_max_throughput experiment data and plot per container (using payload)\n",
    "\n",
    "# Define directories\n",
    "experiment_dir = os.path.join(\"..\", \"results\", \"04_grpc_max_throughput\")\n",
    "output_dir  = os.path.join(\"..\", \"diagrams\", \"04_grpc_max_throughput\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get all metrics CSV files in the experiment directory\n",
    "csv_files = glob.glob(os.path.join(experiment_dir, 'metrics_*.csv'))\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in:\", experiment_dir)\n",
    "else:\n",
    "    # Load each CSV and extract additional parameters (mesh, qps, payload)\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        df = load_metrics_csv(file)\n",
    "        mesh, qps, payload = extract_mesh_qps_payload(file)\n",
    "        df['mesh'] = mesh\n",
    "        df['qps'] = qps\n",
    "        df['payload'] = payload\n",
    "        df_list.append(df)\n",
    "    df_exp = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Identify unique qps and payload values\n",
    "    unique_qps = sorted(df_exp['qps'].dropna().unique())\n",
    "    unique_payload = sorted(df_exp['payload'].dropna().unique())\n",
    "    \n",
    "    # For the purpose of these diagrams, we assume qps is fixed; if not, select an appropriate value.\n",
    "    qps_val = unique_qps[0] if unique_qps else None\n",
    "    \n",
    "    # For each unique payload value, generate separate diagrams for each metric.\n",
    "    for payload_val in unique_payload:\n",
    "        # Filter the DataFrame for the current payload value.\n",
    "        df_subset = df_exp[df_exp['payload'] == payload_val]\n",
    "        for metric, ylabel in [('cpu', \"CPU Usage (millicore)\"), ('memory', \"Memory Usage (MB)\")]:\n",
    "            max_metric = df_subset.groupby(['namespace', 'container'])[metric].max()\n",
    "            labels = [shorten_label(ns, c) for ns, c in max_metric.index]\n",
    "\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            max_metric.index = labels\n",
    "            max_metric.plot(kind='bar')\n",
    "            plt.xlabel(\"Container\")\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.title(f\"04_grpc_max_throughput: Average {ylabel} (qps = {qps_val}, payload = {payload_val})\")\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"{metric}_{qps_val}_{payload_val}.png\")\n",
    "            plt.savefig(output_path)\n",
    "            plt.close()\n",
    "            print(\"Saved plot to\", output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
