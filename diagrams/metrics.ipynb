{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìà Metrics Analysis Notebook\n",
    "\n",
    "This notebook analyzes **CPU** and **Memory** resource usage during performance experiments using Fortio and a service mesh (Istio or Linkerd). It reads resource usage data exported in CSV format from the Kubernetes metrics API and generates visualizations per container.\n",
    "\n",
    "## üìÅ Expected Input\n",
    "\n",
    "- CSV files under `../results/<experiment>/metrics_<mesh>_<qps>_<payload>_<replicas>_<timestamp>.csv`\n",
    "- Structure:\n",
    "    - `timestamp, namespace, pod, container, cpu(n), memory(Ki)`\n",
    "    - Plus derived fields: `cpu` (as float), `memory` (as float)\n",
    "\n",
    "## üìâ Output\n",
    "\n",
    "- CPU and Memory bar charts per container for each experiment setup.\n",
    "- Output PNGs are saved in:\n",
    "    - `../diagrams/<experiment>/cpu_*.png`\n",
    "    - `../diagrams/<experiment>/memory_*.png`\n",
    "\n",
    "> üìå **Note**: CPU values are shown in nanocores, and memory in Ki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import colormaps\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cpu(cpu_str):\n",
    "    \"\"\"\n",
    "    Convert CPU usage strings to millicores (m).\n",
    "\n",
    "    Conversions:\n",
    "      - '123n' ‚Üí nanocores ‚Üí 0.000123 m\n",
    "      - '123u' ‚Üí microcores ‚Üí 0.123 m\n",
    "      - '123m' ‚Üí millicores ‚Üí 123.0 m\n",
    "      - '123'  ‚Üí cores     ‚Üí 123000.0 m\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s = cpu_str.lower().strip()\n",
    "        if s.endswith('n'):\n",
    "            value = float(s[:-1])\n",
    "            return value / 1e6\n",
    "        elif s.endswith('u'):\n",
    "            value = float(s[:-1])\n",
    "            return value / 1e3\n",
    "        elif s.endswith('m'):\n",
    "            return float(s[:-1])\n",
    "        else:\n",
    "            value = float(s)\n",
    "            return value * 1000.0\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting CPU value '{cpu_str}': {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_memory(mem_str):\n",
    "    \"\"\"\n",
    "    Convert memory usage from a string (which might be in Ki, Mi, or Gi) to a float representing megabytes (MB).\n",
    "    \n",
    "    Conversions:\n",
    "    - If the value ends with \"Ki\": MB = (numeric value) / 1024.\n",
    "    - If the value ends with \"Mi\": MB = numeric value.\n",
    "    - If the value ends with \"Gi\": MB = (numeric value) * 1024.\n",
    "    - If no known suffix, attempt direct conversion.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if mem_str.endswith(\"Ki\"):\n",
    "            value = float(mem_str[:-2])\n",
    "            mb = value / 1024.0\n",
    "            return mb\n",
    "        elif mem_str.endswith(\"Mi\"):\n",
    "            value = float(mem_str[:-2])\n",
    "            # Assuming 1 MiB is reported as 1 MB\n",
    "            return value\n",
    "        elif mem_str.endswith(\"Gi\"):\n",
    "            value = float(mem_str[:-2])\n",
    "            return value * 1024.0\n",
    "        else:\n",
    "            # If no unit present, try converting directly\n",
    "            return float(mem_str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting memory value '{mem_str}': {e}\")\n",
    "        return None\n",
    "\n",
    "def get_bar_colors(groups):\n",
    "    \"\"\"\n",
    "    Return a list of colors for given stacking groups.\n",
    "    Specific proxy groups get fixed colors; all other groups use distinct\n",
    "    entries from matplotlib's tab10 palette to avoid everything green.\n",
    "    \"\"\"\n",
    "    proxy_map = {\n",
    "        # Control Plane components\n",
    "        'destination': 'tab:blue',\n",
    "        'discovery': 'tab:orange',\n",
    "        'identity': 'tab:green',\n",
    "        'linkerd-proxy': 'tab:red',\n",
    "        'policy': 'tab:purple',\n",
    "        'proxy-injector': 'tab:brown',\n",
    "        'sp-validator': 'tab:cyan',\n",
    "        # Data-plane proxies\n",
    "        'ztunnel': 'darkorange',\n",
    "        'waypoint': 'orange',\n",
    "        'client-proxy': 'darkblue',\n",
    "        'server-proxy': 'blue'\n",
    "    }\n",
    "    from matplotlib import cm\n",
    "    palette = colormaps['tab10']\n",
    "    assigned = {}\n",
    "    other_idx = 0\n",
    "    colors = []\n",
    "    for g in groups:\n",
    "        if g in proxy_map:\n",
    "            colors.append(proxy_map[g])\n",
    "        else:\n",
    "            if g not in assigned:\n",
    "                assigned[g] = palette(other_idx % palette.N)\n",
    "                other_idx += 1\n",
    "            colors.append(assigned[g])\n",
    "    return colors\n",
    "\n",
    "def assign_stack_group(df):\n",
    "    \"\"\"\n",
    "    Create a 'stack_group' column:\n",
    "      - For proxies, assign one of ['ztunnel', 'waypoint', 'client-proxy', 'server-proxy']\n",
    "      - For other containers, use the container name.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    conditions = [\n",
    "        (df['container'] == 'istio-proxy') & df['pod'].str.contains('ztunnel'),\n",
    "        (df['container'] == 'istio-proxy') & df['pod'].str.contains('waypoint'),\n",
    "        df['container'].isin(['istio-proxy', 'linkerd-proxy']) & df['pod'].str.contains('client'),\n",
    "        df['container'].isin(['istio-proxy', 'linkerd-proxy']) & df['pod'].str.contains('server')\n",
    "    ]\n",
    "    choices = ['ztunnel', 'waypoint', 'client-proxy', 'server-proxy']\n",
    "    df['stack_group'] = np.select(conditions, choices, default=df['container'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metrics_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file with resource metrics, parses the timestamp, and converts the raw CPU\n",
    "    (nanocores remain unchanged) and memory values (in Ki).\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame with columns:\n",
    "        - timestamp\n",
    "        - namespace\n",
    "        - pod\n",
    "        - container\n",
    "        - cpu(n) (original)\n",
    "        - memory(Ki) (original)\n",
    "        - cpu: numeric CPU in millicore\n",
    "        - memory: numeric memory in MB\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['cpu'] = df['cpu(n)'].apply(convert_cpu)\n",
    "    df['memory'] = df['memory(Ki)'].apply(convert_memory)\n",
    "    return df\n",
    "\n",
    "def extract_mesh_qps_payload_replicas(filename):\n",
    "    \"\"\"\n",
    "    Extract mesh, qps, and payload from a filename assumed to be formatted as:\n",
    "      metrics_<mesh>_<qps>_<payload>_<replicas>_<timestamp>.csv\n",
    "    Returns a tuple: (mesh (str), qps (int), payload (int), replicas (int)).\n",
    "    \"\"\"\n",
    "    base = os.path.basename(filename)\n",
    "    parts = base.replace(\"metrics_\", \"\").replace(\".csv\", \"\").split(\"_\")\n",
    "    if len(parts) < 3:\n",
    "        return None, None, None\n",
    "    mesh, qps, payload, replicas = parts[0], parts[1], parts[2], parts[3]\n",
    "    return mesh, int(qps), int(payload), int(replicas)\n",
    "\n",
    "def shorten_label(ns, pod, container, max_len=18):\n",
    "    \"\"\"\n",
    "    Shortens the namespace, pod, and container names to a maximum length.\n",
    "    If the name exceeds max_len, it truncates the string and appends '..'.\n",
    "    Returns a formatted string: \"ns/pod/container\".\n",
    "    \"\"\"\n",
    "    ns_abbr = ns if len(ns) <= max_len else ns[:max_len - 2] + '..'\n",
    "    pod_abbr = pod if len(pod) <= max_len else pod[:max_len - 2] + '..'\n",
    "    container_abbr = container if len(container) <= max_len else container[:max_len - 2] + '..'\n",
    "    return f\"{ns_abbr}/{pod_abbr}/{container_abbr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP Max throughput experiment (experiment 1)\n",
    "experiment_pattern = os.path.join(\"..\", \"results\", \"*\", \"01_http_max_throughput\", \"metrics_*.csv\")\n",
    "output_dir         = os.path.join(\"..\", \"diagrams\", \"01_http_max_throughput\")\n",
    "csv_files          = glob.glob(experiment_pattern)\n",
    "title              = \"Experiment 1 - Max Throughput {name}\\n(Prot=HTTP, QPS={qps}, Payload={payload}, Metric={metric}, Replicas={replicas})\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in:\", experiment_pattern)\n",
    "else:\n",
    "    # ‚îÄ‚îÄ‚îÄ LOAD & TAG EACH ROW WITH ITS MESH ‚îÄ‚îÄ‚îÄ\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        df = load_metrics_csv(file)\n",
    "        mesh, qps, payload, replicas = extract_mesh_qps_payload_replicas(file)\n",
    "        df['mesh'] = mesh\n",
    "        df['qps']  = qps\n",
    "        df['payload'] = payload\n",
    "        df['replicas'] = replicas\n",
    "        df_list.append(df)\n",
    "    df_exp = pd.concat(df_list, ignore_index=True)\n",
    "    df_exp = df_exp.dropna(subset=[\"mesh\", \"cpu\", \"memory\"])\n",
    "\n",
    "    # # ‚îÄ‚îÄ‚îÄ GLOBAL MAX PER CONTAINER ‚îÄ‚îÄ‚îÄ\n",
    "    # for metric, ylabel in [(\"cpu\", \"CPU Usage (millicore)\"), (\"memory\", \"Memory Usage (MB)\")]:\n",
    "    #     max_vals = df_exp.groupby([\"namespace\", \"pod\", \"container\"])[metric].max()\n",
    "    #     labels   = [shorten_label(ns, pod, ctr) for (ns, pod, ctr) in max_vals.index]\n",
    "    #     plt.figure(figsize=(15, 10))\n",
    "    #     plt.bar(labels, max_vals.values,color=\"tab:orange\", edgecolor=\"white\", linewidth=1)\n",
    "    #     plt.grid(axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "    #     plt.title(title.format(name=\"Global\", qps=qps, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "    #     plt.ylabel(ylabel)\n",
    "    #     plt.xticks(ha=\"right\")\n",
    "    #     plt.tight_layout()\n",
    "    #     plt.savefig(os.path.join(output_dir, f\"{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "    #     plt.close()\n",
    "\n",
    "    for plane, name in [(\"control-plane\", \"Control Plane\"), (\"data-plane\", \"Data Plane\")]:\n",
    "        df_plane = df_exp[df_exp[\"group\"] == plane].copy()\n",
    "        df_plane = assign_stack_group(df_plane)\n",
    "        collapsed = (df_plane.groupby([\"mesh\", \"stack_group\", \"pod\"]).agg({\"cpu\": \"max\", \"memory\": \"max\"}).reset_index())\n",
    "        agg = (collapsed.groupby([\"mesh\", \"stack_group\"]).agg({\"cpu\": \"sum\", \"memory\": \"sum\"}).reset_index())\n",
    "        for metric, ylabel in [(\"cpu\", \"CPU Usage (millicore)\"), (\"memory\", \"Memory Usage (MB)\")]:\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  STACKED CONTROL-PLANE & DATA-PLANE TOTALS  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "            pivot = (agg.pivot_table(index=\"mesh\",columns=\"stack_group\",values=metric,fill_value=0).sort_index(axis=1))\n",
    "            colors = get_bar_colors(pivot.columns)\n",
    "            pivot.plot(kind=\"bar\",stacked=True,figsize=(15, 10),color=colors,edgecolor=\"white\",linewidth=1)\n",
    "            plt.grid(axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "            plt.title(title.format(name=name, qps=\"MAX\", payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.xticks(ha=\"right\")\n",
    "            plt.legend(title=\"\")\n",
    "            plt.tight_layout()\n",
    "            suffix = \"control_plane\" if plane == \"control-plane\" else \"data_plane\"\n",
    "            plt.savefig(os.path.join(output_dir,f\"{suffix}_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS CUMULATIVE (Elapsed Time Per Mesh) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "            metric_ts = (df_plane.groupby(['timestamp', 'mesh'])[metric].sum().reset_index())\n",
    "            metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "            plt.figure(figsize=(15,10))\n",
    "            for mesh_name in ['istio', 'linkerd']:\n",
    "                df_m = metric_ts[metric_ts['mesh'] == mesh_name]\n",
    "                plt.plot(df_m['elapsed_s'], df_m[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {name}\")\n",
    "            plt.title(title.format(name=name, qps=\"MAX\", payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "            plt.xlabel(\"Time (seconds)\")\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.legend()\n",
    "            plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_cumulative_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS (Elapsed Time Per Mesh & Component) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "            metric_ts = (df_plane.groupby(['timestamp', 'mesh', 'stack_group'])[metric].sum().reset_index())\n",
    "            metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for mesh_name in ['istio', 'linkerd']:\n",
    "                for comp in metric_ts.loc[metric_ts['mesh'] == mesh_name, 'stack_group'].unique():\n",
    "                    df_line = metric_ts[(metric_ts['mesh'] == mesh_name) & (metric_ts['stack_group'] == comp)]\n",
    "                    plt.plot(df_line['elapsed_s'], df_line[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {comp}\")\n",
    "            plt.title(title.format(name=name, qps=\"MAX\", payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "            plt.xlabel(\"Time (seconds)\")\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.legend(ncol=2, frameon=False)\n",
    "            plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gRPC Max throughput experiment (experiment 2)\n",
    "experiment_pattern = os.path.join(\"..\", \"results\", \"*\", \"02_grpc_max_throughput\", \"metrics_*.csv\")\n",
    "output_dir         = os.path.join(\"..\", \"diagrams\", \"02_grpc_max_throughput\")\n",
    "csv_files          = glob.glob(experiment_pattern)\n",
    "title              = \"Experiment 2 - Max Throughput {name}\\n(Prot=gRPC, QPS={qps}, Payload={payload}, Metric={metric}, Replicas={replicas})\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in:\", experiment_pattern)\n",
    "else:\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LOAD & TAG MESH ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        df = load_metrics_csv(file)\n",
    "        mesh, qps, payload, replicas = extract_mesh_qps_payload_replicas(file)\n",
    "        df['mesh'] = mesh\n",
    "        df['qps']  = qps\n",
    "        df['payload'] = payload\n",
    "        df['replicas'] = replicas\n",
    "        df_list.append(df)\n",
    "    df_exp = pd.concat(df_list, ignore_index=True)\n",
    "    df_exp = df_exp.dropna(subset=[\"mesh\", \"cpu\", \"memory\"])\n",
    "\n",
    "    # # ‚îÄ‚îÄ‚îÄ GLOBAL MAX PER CONTAINER ‚îÄ‚îÄ‚îÄ\n",
    "    # for metric, ylabel in [(\"cpu\", \"CPU Usage (millicore)\"), (\"memory\", \"Memory Usage (MB)\")]:\n",
    "    #     max_vals = df_exp.groupby([\"namespace\",\"pod\",\"container\"])[metric].max()\n",
    "    #     labels   = [shorten_label(ns, pod, ctr)for (ns, pod, ctr) in max_vals.index]\n",
    "    #     plt.figure(figsize=(15,10))\n",
    "    #     plt.bar(labels, max_vals.values,color=\"tab:orange\", edgecolor=\"white\", linewidth=1)\n",
    "    #     plt.grid(axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "    #     plt.title(f\"Experiment 2 - Max Throughput\\n\"f\"(Prot=gRPC, QPS={qps}, Metric={metric.upper()})\")\n",
    "    #     plt.ylabel(ylabel)\n",
    "    #     plt.xticks(ha=\"right\")\n",
    "    #     plt.tight_layout()\n",
    "    #     plt.savefig(os.path.join(output_dir, f\"{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "    #     plt.close()\n",
    "\n",
    "    for plane, name in [(\"control-plane\",\"Control Plane\"), (\"data-plane\",\"Data Plane\")]:\n",
    "        df_plane = df_exp[df_exp[\"group\"] == plane].copy()\n",
    "        df_plane = assign_stack_group(df_plane)\n",
    "        collapsed = (df_plane.groupby([\"mesh\",\"stack_group\",\"pod\"]).agg({\"cpu\":\"max\",\"memory\":\"max\"}).reset_index())\n",
    "        agg = (collapsed.groupby([\"mesh\",\"stack_group\"]).agg({\"cpu\":\"sum\",\"memory\":\"sum\"}).reset_index())\n",
    "        for metric, ylabel in [(\"cpu\",\"CPU Usage (millicore)\"), (\"memory\",\"Memory Usage (MB)\")]:\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  STACKED CONTROL-PLANE & DATA-PLANE TOTALS  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "            pivot = (agg.pivot_table(index=\"mesh\",columns=\"stack_group\",values=metric,fill_value=0).sort_index(axis=1))\n",
    "            colors = get_bar_colors(pivot.columns)\n",
    "            pivot.plot(kind=\"bar\",stacked=True,figsize=(15, 10),color=colors,edgecolor=\"white\",linewidth=1)\n",
    "            plt.grid(axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "            plt.title(title.format(name=name, qps=\"MAX\", payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.xticks(ha=\"right\")\n",
    "            plt.legend(title=\"\")\n",
    "            plt.tight_layout()\n",
    "            suffix = \"control_plane\" if plane == \"control-plane\" else \"data_plane\"\n",
    "            plt.savefig(os.path.join(output_dir,f\"{suffix}_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS CUMULATIVE (Elapsed Time Per Mesh) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "            metric_ts = (df_plane.groupby(['timestamp', 'mesh'])[metric].sum().reset_index())\n",
    "            metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "            plt.figure(figsize=(15,10))\n",
    "            for mesh_name in ['istio', 'linkerd']:\n",
    "                df_m = metric_ts[metric_ts['mesh'] == mesh_name]\n",
    "                plt.plot(df_m['elapsed_s'], df_m[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {name}\")\n",
    "            plt.title(title.format(name=name, qps=\"MAX\", payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "            plt.xlabel(\"Time (seconds)\")\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.legend()\n",
    "            plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_cumulative_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS (Elapsed Time Per Mesh & Component) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "            metric_ts = (df_plane.groupby(['timestamp', 'mesh', 'stack_group'])[metric].sum().reset_index())\n",
    "            metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for mesh_name in ['istio', 'linkerd']:\n",
    "                for comp in metric_ts.loc[metric_ts['mesh'] == mesh_name, 'stack_group'].unique():\n",
    "                    df_line = metric_ts[(metric_ts['mesh'] == mesh_name) & (metric_ts['stack_group'] == comp)]\n",
    "                    plt.plot(df_line['elapsed_s'], df_line[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {comp}\")\n",
    "            plt.title(title.format(name=name, qps=\"MAX\", payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "            plt.xlabel(\"Time (seconds)\")\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.legend(ncol=2, frameon=False)\n",
    "            plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP Constant throughput experiment (experiment 3)\n",
    "experiment_pattern = os.path.join(\"..\", \"results\", \"*\", \"03_http_constant_throughput\", \"metrics_*.csv\")\n",
    "output_dir         = os.path.join(\"..\", \"diagrams\", \"03_http_constant_throughput\")\n",
    "csv_files          = glob.glob(experiment_pattern)\n",
    "title              = \"Experiment 3 - Constant Throughput {name}\\n(Prot=HTTP, QPS={qps}, Payload={payload}, Metric={metric}, Replicas={replicas})\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in:\", experiment_pattern)\n",
    "else:\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LOAD & TAG MESH + QPS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        df = load_metrics_csv(file)\n",
    "        mesh, qps, payload, replicas = extract_mesh_qps_payload_replicas(file)\n",
    "        df['mesh'] = mesh\n",
    "        df['qps']  = qps\n",
    "        df['payload'] = payload\n",
    "        df['replicas'] = replicas\n",
    "        df_list.append(df)\n",
    "    df_exp = pd.concat(df_list, ignore_index=True)\n",
    "    df_exp = df_exp.dropna(subset=['mesh','cpu','memory','qps'])\n",
    "    unique_qps = sorted(df_exp['qps'].unique())\n",
    "\n",
    "    # # ‚îÄ‚îÄ‚îÄ GLOBAL MAX PER CONTAINER ‚îÄ‚îÄ‚îÄ\n",
    "    # for metric, ylabel in [('cpu','CPU Usage (millicore)'), ('memory','Memory Usage (MB)')]:\n",
    "    #     for qps in unique_qps:\n",
    "    #         df_q = df_exp[df_exp['qps'] == qps]\n",
    "    #         max_vals = df_q.groupby(['mesh','namespace','pod','container'])[metric].max()\n",
    "    #         labels   = [shorten_label(ns, pod, ctr) for (_, ns, pod, ctr) in max_vals.index]\n",
    "    #         plt.figure(figsize=(15,10))\n",
    "    #         plt.bar(labels, max_vals.values,color='tab:orange', edgecolor='white', linewidth=1)\n",
    "    #         plt.grid(axis='y', linestyle='--', linewidth=0.5)\n",
    "    #         plt.title(title.format(name=name, qps=qps, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "    #         plt.ylabel(ylabel)\n",
    "    #         plt.xticks(ha='right')\n",
    "    #         plt.tight_layout()\n",
    "    #         plt.savefig(os.path.join(output_dir, f\"{metric}_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "    #         plt.close()\n",
    "\n",
    "    for plane, name in [('control-plane','Control Plane'),('data-plane','Data Plane')]:\n",
    "        df_plane = df_exp[df_exp['group'] == plane].copy()\n",
    "        df_plane = assign_stack_group(df_plane)\n",
    "        collapsed = (df_plane.groupby(['mesh','qps','stack_group','pod']).agg({'cpu':'max','memory':'max'}).reset_index())\n",
    "        agg = (collapsed.groupby(['mesh','qps','stack_group']).agg({'cpu':'sum','memory':'sum'}).reset_index())\n",
    "        for qps in unique_qps:\n",
    "            for metric, ylabel in [('cpu','CPU Usage (millicore)'),('memory','Memory Usage (MB)')]:\n",
    "\n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  STACKED CONTROL-PLANE & DATA-PLANE TOTALS  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                pivot = (agg[agg['qps'] == qps].pivot_table(index='mesh',columns='stack_group',values=metric,fill_value=0).sort_index(axis=1))\n",
    "                colors = get_bar_colors(pivot.columns)\n",
    "                pivot.plot(kind='bar',stacked=True,figsize=(15,10),color=colors,edgecolor='white',linewidth=1)\n",
    "                plt.grid(axis='y', linestyle='--', linewidth=0.5)\n",
    "                plt.title(title.format(name=name, qps=qps, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.xticks(ha='right')\n",
    "                plt.legend(title='')\n",
    "                plt.tight_layout()\n",
    "                suffix = 'control_plane' if plane=='control-plane' else 'data_plane'\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()\n",
    "\n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS CUMULATIVE (Elapsed Time Per Mesh) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                df_plane_q = df_plane[df_plane['qps'] == qps]\n",
    "                metric_ts = (df_plane_q.groupby(['timestamp', 'mesh'])[metric].sum().reset_index())\n",
    "                metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds())\n",
    "                )\n",
    "                plt.figure(figsize=(15,10))\n",
    "                for mesh_name in ['istio', 'linkerd']:\n",
    "                    df_m = metric_ts[metric_ts['mesh'] == mesh_name]\n",
    "                    plt.plot(df_m['elapsed_s'], df_m[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {name}\")\n",
    "                plt.title(title.format(name=name, qps=qps, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.xlabel(\"Time (seconds)\")\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.legend()\n",
    "                plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_cumulative_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()\n",
    "\n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS (Elapsed Time Per Mesh & Component) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                metric_ts = (df_plane_q.groupby(['timestamp', 'mesh', 'stack_group'])[metric].sum().reset_index())\n",
    "                metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "                plt.figure(figsize=(10,6))\n",
    "                for mesh_name in ['istio', 'linkerd']:\n",
    "                    for comp in metric_ts.loc[metric_ts['mesh']==mesh_name, 'stack_group'].unique():\n",
    "                        df_line = metric_ts[(metric_ts['mesh'] == mesh_name) & (metric_ts['stack_group'] == comp)]\n",
    "                        plt.plot(df_line['elapsed_s'], df_line[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {comp}\")\n",
    "                plt.title(title.format(name=name, qps=qps, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.xlabel(\"Time (seconds)\")\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.legend(ncol=2, frameon=False)\n",
    "                plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gRPC Constant throughput experiment (experiment 4)\n",
    "experiment_pattern = os.path.join(\"..\", \"results\", \"*\", \"04_grpc_constant_throughput\", \"metrics_*.csv\")\n",
    "output_dir         = os.path.join(\"..\", \"diagrams\", \"04_grpc_constant_throughput\")\n",
    "csv_files          = glob.glob(experiment_pattern)\n",
    "title              = \"Experiment 4 - Constant Throughput {name}\\n(Prot=gRPC, QPS={qps}, Payload={payload}, Metric={metric}, Replicas={replicas})\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in:\", experiment_pattern)\n",
    "else:\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LOAD & TAG MESH + QPS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        df = load_metrics_csv(file)\n",
    "        mesh, qps, payload, replicas = extract_mesh_qps_payload_replicas(file)\n",
    "        df['mesh'] = mesh\n",
    "        df['qps']  = qps\n",
    "        df['payload'] = payload\n",
    "        df['replicas'] = replicas\n",
    "        df_list.append(df)\n",
    "    df_exp = pd.concat(df_list, ignore_index=True)\n",
    "    df_exp = df_exp.dropna(subset=['mesh','cpu','memory','qps'])\n",
    "    unique_qps = sorted(df_exp['qps'].unique())\n",
    "\n",
    "    # # ‚îÄ‚îÄ‚îÄ GLOBAL MAX PER CONTAINER ‚îÄ‚îÄ‚îÄ\n",
    "    # for metric, ylabel in [('cpu','CPU Usage (millicore)'), ('memory','Memory Usage (MB)')]:\n",
    "    #     for qps in unique_qps:\n",
    "    #         df_q = df_exp[df_exp['qps'] == qps]\n",
    "    #         max_vals = df_q.groupby(['mesh','namespace','pod','container'])[metric].max()\n",
    "    #         labels   = [shorten_label(ns, pod, ctr) for (_, ns, pod, ctr) in max_vals.index]\n",
    "    #         plt.figure(figsize=(15,10))\n",
    "    #         plt.bar(labels, max_vals.values,color='tab:orange', edgecolor='white', linewidth=1)\n",
    "    #         plt.grid(axis='y', linestyle='--', linewidth=0.5)\n",
    "    #         plt.title(title.format(name=name, qps=qps, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "    #         plt.ylabel(ylabel)\n",
    "    #         plt.xticks(ha='right')\n",
    "    #         plt.tight_layout()\n",
    "    #         plt.savefig(os.path.join(output_dir, f\"{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "    #         plt.close()\n",
    "\n",
    "    for plane, name in [('control-plane','Control Plane'),('data-plane','Data Plane')]:\n",
    "        df_plane = df_exp[df_exp['group'] == plane].copy()\n",
    "        df_plane = assign_stack_group(df_plane)\n",
    "        collapsed = (df_plane.groupby(['mesh','qps','stack_group','pod']).agg({'cpu':'max','memory':'max'}).reset_index())\n",
    "        agg = (collapsed.groupby(['mesh','qps','stack_group']).agg({'cpu':'sum','memory':'sum'}).reset_index())\n",
    "        for qps in unique_qps:\n",
    "            for metric, ylabel in [('cpu','CPU Usage (millicore)'),('memory','Memory Usage (MB)')]:\n",
    "\n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  STACKED CONTROL-PLANE & DATA-PLANE TOTALS  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                pivot = (agg[agg['qps'] == qps].pivot_table(index='mesh',columns='stack_group',values=metric,fill_value=0).sort_index(axis=1))\n",
    "                colors = get_bar_colors(pivot.columns)\n",
    "                pivot.plot(kind='bar', stacked=True, figsize=(15,10),color=colors, edgecolor='white', linewidth=1)\n",
    "                plt.grid(axis='y', linestyle='--', linewidth=0.5)\n",
    "                plt.title(title.format(name=name, qps=qps, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.xticks(ha='right')\n",
    "                plt.legend(title='')\n",
    "                plt.tight_layout()\n",
    "                suffix = 'control_plane' if plane=='control-plane' else 'data_plane'\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()\n",
    "\n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS CUMULATIVE (Elapsed Time Per Mesh) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                df_plane_q = df_plane[df_plane['qps'] == qps]\n",
    "                metric_ts = (df_plane_q.groupby(['timestamp', 'mesh'])[metric].sum().reset_index())\n",
    "                metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "                plt.figure(figsize=(15,10))\n",
    "                for mesh_name in ['istio', 'linkerd']:\n",
    "                    df_m = metric_ts[metric_ts['mesh'] == mesh_name]\n",
    "                    plt.plot(df_m['elapsed_s'], df_m[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {name}\")\n",
    "                plt.title(title.format(name=name, qps=qps, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.xlabel(\"Time (seconds)\")\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.legend()\n",
    "                plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_cumulative_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()\n",
    "\n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS (Elapsed Time Per Mesh & Component) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                metric_ts = (df_plane_q.groupby(['timestamp', 'mesh', 'stack_group'])[metric].sum().reset_index())\n",
    "                metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "                plt.figure(figsize=(10,6))\n",
    "                for mesh_name in ['istio', 'linkerd']:\n",
    "                    for comp in metric_ts.loc[metric_ts['mesh']==mesh_name, 'stack_group'].unique():\n",
    "                        df_line = metric_ts[(metric_ts['mesh'] == mesh_name) & (metric_ts['stack_group'] == comp)]\n",
    "                        plt.plot(df_line['elapsed_s'], df_line[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {comp}\")\n",
    "                plt.title(title.format(name=name, qps=qps, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.xlabel(\"Time (seconds)\")\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.legend(ncol=2, frameon=False)\n",
    "                plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP Constant throughput with Payload experiment (experiment 5)\n",
    "experiment_pattern = os.path.join(\"..\", \"results\", \"*\", \"05_http_payload\", \"metrics_*.csv\")\n",
    "output_dir         = os.path.join(\"..\", \"diagrams\", \"05_http_payload\")\n",
    "csv_files          = glob.glob(experiment_pattern)\n",
    "title              = \"Experiment 5 - Constant Throughput with Payload {name}\\n(Prot=HTTP, QPS={qps}, Payload={payload}, Metric={metric}, Replicas={replicas})\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in:\", experiment_pattern)\n",
    "else:\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LOAD & TAG MESH + QPS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        df = load_metrics_csv(file)\n",
    "        mesh, qps, payload, replicas = extract_mesh_qps_payload_replicas(file)\n",
    "        df['mesh']    = mesh\n",
    "        df['qps']     = qps\n",
    "        df['payload'] = payload\n",
    "        df['replicas'] = replicas\n",
    "        df_list.append(df)\n",
    "    df_exp = pd.concat(df_list, ignore_index=True)\n",
    "    df_exp = df_exp.dropna(subset=['mesh','cpu','memory','qps','payload'])\n",
    "\n",
    "    unique_qps     = sorted(df_exp['qps'].unique())\n",
    "    unique_payload = sorted(df_exp['payload'].unique())\n",
    "    qps_val = unique_qps[0] if unique_qps else None\n",
    "\n",
    "    for payload in unique_payload:\n",
    "        df_p = df_exp[df_exp['payload'] == payload]\n",
    "\n",
    "        # # ‚îÄ‚îÄ‚îÄ GLOBAL MAX PER CONTAINER ‚îÄ‚îÄ‚îÄ\n",
    "        # for metric, ylabel in [('cpu','CPU Usage (millicore)'), ('memory','Memory Usage (MB)')]:\n",
    "        #     max_vals = df_p.groupby(['namespace','pod','container'])[metric].max()\n",
    "        #     labels   = [shorten_label(ns,pod,ctr) for ns,pod,ctr in max_vals.index]\n",
    "        #     plt.figure(figsize=(15,10))\n",
    "        #     plt.bar(labels, max_vals.values,color='tab:orange', edgecolor='white', linewidth=1)\n",
    "        #     plt.grid(axis='y', linestyle='--', linewidth=0.5)\n",
    "        #     plt.title(f\"Experiment 5 - Constant Throughput\\nProt=HTTP, QPS={qps_val}, Payload={payload}, Metric={metric.upper()}\")\n",
    "        #     plt.ylabel(ylabel)\n",
    "        #     plt.xticks(ha='right')\n",
    "        #     plt.tight_layout()\n",
    "        #     plt.savefig(os.path.join(output_dir, f\"{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "        #     plt.close()\n",
    "\n",
    "        for plane, name in [('control-plane','Control Plane'), ('data-plane','Data Plane')]:\n",
    "            df_plane = df_p[df_p['group'] == plane].copy()\n",
    "            df_plane = assign_stack_group(df_plane)\n",
    "            collapsed = (df_plane.groupby(['mesh','qps','payload','stack_group','pod']).agg({'cpu':'max','memory':'max'}).reset_index())\n",
    "            agg = (collapsed.groupby(['mesh','qps','payload','stack_group']).agg({'cpu':'sum','memory':'sum'}).reset_index())\n",
    "            for metric, ylabel in [('cpu','CPU Usage (millicore)'), ('memory','Memory Usage (MB)')]:\n",
    "\n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  STACKED CONTROL-PLANE & DATA-PLANE TOTALS  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                pivot = (agg[agg['payload']==payload].pivot_table(index='mesh',columns='stack_group',values=metric,fill_value=0).sort_index(axis=1))\n",
    "                colors = get_bar_colors(pivot.columns)\n",
    "                pivot.plot(kind='bar', stacked=True, figsize=(15,10),color=colors, edgecolor='white', linewidth=1)\n",
    "                plt.grid(axis='y', linestyle='--', linewidth=0.5)\n",
    "                plt.title(title.format(name=name, qps=qps_val, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.xticks(ha='right')\n",
    "                plt.legend(title='')\n",
    "                plt.tight_layout()\n",
    "                suffix = 'control_plane' if plane=='control-plane' else 'data_plane'\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()\n",
    "        \n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS CUMULATIVE (Elapsed Time Per Mesh) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                metric_ts = (df_plane.groupby(['timestamp', 'mesh'])[metric].sum().reset_index())\n",
    "                metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "                plt.figure(figsize=(15,10))\n",
    "                for mesh_name in ['istio', 'linkerd']:\n",
    "                    df_m = metric_ts[metric_ts['mesh'] == mesh_name]\n",
    "                    plt.plot(df_m['elapsed_s'],df_m[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {name}\")\n",
    "                plt.title(title.format(name=name, qps=qps_val, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.xlabel(\"Time (seconds)\")\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.legend()\n",
    "                plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_cumulative_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()\n",
    "\n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS (Elapsed Time Per Mesh & Component) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                metric_ts = (df_plane.groupby(['timestamp','mesh','stack_group'])[metric].sum().reset_index())\n",
    "                metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                for mesh_name in ['istio', 'linkerd']:\n",
    "                    for comp in metric_ts.loc[metric_ts['mesh'] == mesh_name, 'stack_group'].unique():\n",
    "                        df_line = metric_ts[(metric_ts['mesh'] == mesh_name) & (metric_ts['stack_group'] == comp)]\n",
    "                        plt.plot(df_line['elapsed_s'],df_line[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {comp}\")\n",
    "                plt.title(title.format(name=name, qps=qps_val, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.xlabel(\"Time (seconds)\")\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.legend(ncol=2, frameon=False)\n",
    "                plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP Constant throughput with HTTPRoute header-based routing experiment (experiment 6)\n",
    "experiment_pattern = os.path.join(\"..\", \"results\", \"*\", \"06_http_constant_throughput_header\", \"metrics_*.csv\")\n",
    "output_dir         = os.path.join(\"..\", \"diagrams\", \"06_http_constant_throughput_header\")\n",
    "csv_files          = glob.glob(experiment_pattern)\n",
    "title              = \"Experiment 6 - Constant Throughput with HTTPRoute header-based routing {name}\\n(Prot=HTTP, QPS={qps}, Payload={payload}, Metric={metric}, Replicas={replicas})\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in:\", experiment_pattern)\n",
    "else:\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LOAD & TAG MESH + QPS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        df = load_metrics_csv(file)\n",
    "        mesh, qps, payload, replicas = extract_mesh_qps_payload_replicas(file)\n",
    "        df['mesh']    = mesh\n",
    "        df['qps']     = qps\n",
    "        df['payload'] = payload\n",
    "        df['replicas'] = replicas\n",
    "        df_list.append(df)\n",
    "    df_exp     = pd.concat(df_list, ignore_index=True)\n",
    "    df_exp     = df_exp.dropna(subset=[\"mesh\", \"cpu\", \"memory\", \"qps\"])\n",
    "    unique_qps = sorted(df_exp[\"qps\"].unique())\n",
    "\n",
    "    for qps in unique_qps:\n",
    "        df_qps    = df_exp[df_exp[\"qps\"] == qps]\n",
    "\n",
    "        # # ‚îÄ‚îÄ‚îÄ GLOBAL MAX PER CONTAINER ‚îÄ‚îÄ‚îÄ\n",
    "        # for metric, ylabel in [(\"cpu\", \"CPU Usage (millicore)\"), (\"memory\", \"Memory Usage (MB)\")]:\n",
    "        #     max_vals = df_qps.groupby([\"mesh\", \"namespace\", \"pod\", \"container\"])[metric].max()\n",
    "        #     labels   = [shorten_label(ns, pod, ctr) for _, ns, pod, ctr in max_vals.index]\n",
    "        #     plt.figure(figsize=(15,10))\n",
    "        #     plt.bar(labels, max_vals.values, color=\"tab:orange\")\n",
    "        #     plt.title(title.format(name=name, qps=qps_val, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "        #     plt.ylabel(ylabel)\n",
    "        #     plt.xticks(ha=\"right\")\n",
    "        #     plt.tight_layout()\n",
    "        #     plt.savefig(os.path.join(output_dir, f\"{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "        #     plt.close()\n",
    "        \n",
    "        for plane,name in [(\"control-plane\",\"Control Plane\"), (\"data-plane\",\"Data Plane\")]:\n",
    "            df_plane = df_qps[df_qps[\"group\"] == plane].copy()\n",
    "            df_plane = assign_stack_group(df_plane)\n",
    "            collapsed = (df_plane.groupby([\"mesh\",\"qps\",\"stack_group\",\"pod\"]).agg({\"cpu\":\"max\",\"memory\":\"max\"}).reset_index())\n",
    "            agg = (collapsed.groupby([\"mesh\",\"qps\",\"stack_group\"]).agg({\"cpu\":\"sum\",\"memory\":\"sum\"}).reset_index())\n",
    "            for metric, ylabel in [(\"cpu\",\"CPU Usage (millicore)\"), (\"memory\",\"Memory Usage (MB)\")]:\n",
    "\n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  STACKED CONTROL-PLANE & DATA-PLANE TOTALS  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                pivot = (agg[agg[\"qps\"] == qps].pivot_table(index=\"mesh\",columns=\"stack_group\",values=metric,fill_value=0).sort_index(axis=1))\n",
    "                colors = get_bar_colors(pivot.columns)\n",
    "                pivot.plot(kind=\"bar\",stacked=True,figsize=(15,10),color=colors,edgecolor=\"white\",linewidth=1)\n",
    "                plt.grid(axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "                plt.title(title.format(name=name, qps=qps_val, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.xticks(ha=\"right\")\n",
    "                plt.legend(title=\"\")\n",
    "                plt.tight_layout()\n",
    "                suffix = \"control_plane\" if plane==\"control-plane\" else \"data_plane\"\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()\n",
    "        \n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS COMULATIVE (Elapsed Time Per Mesh) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                metric_ts = (df_plane.groupby([\"timestamp\",\"mesh\"])[metric].sum().reset_index())\n",
    "                metric_ts[\"elapsed_s\"] = (metric_ts.groupby(\"mesh\")[\"timestamp\"].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "                plt.figure(figsize=(15,10))\n",
    "                for mesh_name in [\"istio\", \"linkerd\"]:\n",
    "                    df_m = metric_ts[metric_ts[\"mesh\"] == mesh_name]\n",
    "                    plt.plot(df_m[\"elapsed_s\"],df_m[metric], marker=\"o\", markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {name}\")\n",
    "                plt.title(title.format(name=name, qps=qps_val, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.xlabel(\"Time (seconds)\")\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.legend()\n",
    "                plt.grid(axis=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_comulative_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()\n",
    "\n",
    "                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS (Elapsed Time Per Mesh) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                metric_ts = (df_plane.groupby(['timestamp', 'mesh', 'stack_group'])[metric].sum().reset_index())\n",
    "                metric_ts['elapsed_s'] = metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds())\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                for mesh_name in ['istio', 'linkerd']:\n",
    "                    comps = metric_ts.loc[metric_ts['mesh'] == mesh_name, 'stack_group'].unique()\n",
    "                    for comp in comps:\n",
    "                        df_line = metric_ts[(metric_ts['mesh'] == mesh_name) &(metric_ts['stack_group'] == comp)]\n",
    "                        plt.plot(df_line['elapsed_s'],df_line[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {comp}\")\n",
    "                plt.title(title.format(name=name, qps=qps_val, payload=payload, metric=metric.upper(), replicas=replicas))\n",
    "                plt.xlabel(\"Time (seconds)\")\n",
    "                plt.ylabel(ylabel)\n",
    "                plt.legend(ncol=2, frameon=False)\n",
    "                plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HTTP Constant throughput with multiple replicas experiment (experiment 7)\n",
    "experiment_pattern = os.path.join(\"..\", \"results\", \"*\", \"07_resource_consumption\", \"metrics_*.csv\")\n",
    "output_dir         = os.path.join(\"..\", \"diagrams\", \"07_resource_consumption\")\n",
    "csv_files          = glob.glob(experiment_pattern)\n",
    "title              = \"Experiment 7 - Constant Throughput with Multiple Replicas {name}\\n(Prot=HTTP, QPS={qps}, Payload={payload}, Metric={metric}, Replicas={replicas})\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in:\", experiment_pattern)\n",
    "else:\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LOAD & TAG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        df = load_metrics_csv(file)\n",
    "        mesh, qps, payload, replicas = extract_mesh_qps_payload_replicas(file)\n",
    "        df['mesh']     = mesh\n",
    "        df['qps']      = qps\n",
    "        df['payload']  = payload\n",
    "        df['replicas'] = replicas\n",
    "        df_list.append(df)\n",
    "    df_exp = pd.concat(df_list, ignore_index=True)\n",
    "    df_exp = df_exp.dropna(subset=['cpu', 'memory', 'mesh', 'qps', 'payload'])\n",
    "    unique_qps      = int(df_exp[\"qps\"].unique()[0])\n",
    "    unique_payload  = int(df_exp[\"payload\"].unique()[0])\n",
    "    unique_replicas = int(df_exp[\"replicas\"].unique()[0])\n",
    "\n",
    "    for plane, plane_name in [(\"control-plane\", \"Control Plane\"), (\"data-plane\", \"Data Plane\")]:\n",
    "        df_plane = df_exp[df_exp['group'] == plane].copy()\n",
    "        df_plane = assign_stack_group(df_plane)\n",
    "        collapsed = (df_plane.groupby(['mesh', 'stack_group', 'pod']).agg({'cpu': 'max', 'memory': 'max'}).reset_index())\n",
    "        agg = (collapsed.groupby(['mesh', 'stack_group']).agg({'cpu': 'sum', 'memory': 'sum'}).reset_index())\n",
    "        for metric, ylabel in [('cpu', 'CPU Usage (millicore)'), ('memory', 'Memory Usage (MB)')]:\n",
    "            \n",
    "            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  STACKED CONTROL-PLANE & DATA-PLANE TOTALS  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "            pivot = (agg.pivot_table(index='mesh', columns='stack_group', values=metric, fill_value=0).sort_index(axis=1))\n",
    "            colors = get_bar_colors(pivot.columns)\n",
    "            pivot.plot(kind='bar', stacked=True, figsize=(10, 6), color=colors, edgecolor='white', linewidth=1)\n",
    "            plt.grid(axis='y', linestyle='--', linewidth=0.5)\n",
    "            plt.title(title.format(name=name, qps=unique_qps, payload=unique_payload, metric=metric.upper(), replicas=unique_replicas))\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.xticks(rotation=0)\n",
    "            plt.legend(title='')\n",
    "            plt.tight_layout()\n",
    "            suffix = \"control_plane\" if plane==\"control-plane\" else \"data_plane\"\n",
    "            plt.savefig(os.path.join(output_dir,f\"{suffix}_{metric}_{qps}_{payload}_{replicas}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS COMULATIVE (Elapsed Time Per Mesh) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "            metric_ts = (df_plane.groupby(['timestamp', 'mesh'])[metric].sum().reset_index())\n",
    "            metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for mesh_name in ['istio', 'linkerd']:\n",
    "                df_m = metric_ts[metric_ts['mesh'] == mesh_name]\n",
    "                plt.plot(df_m['elapsed_s'], df_m[metric], marker='o', markersize=1, linewidth=1, label=mesh_name.capitalize())\n",
    "            plt.title(title.format(name=name, qps=unique_qps, payload=unique_payload, metric=metric.upper(), replicas=unique_replicas))\n",
    "            plt.xlabel(\"Time (seconds)\")\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.legend()\n",
    "            plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_comulative_{metric}_{unique_qps}_{unique_payload}_{unique_replicas}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TIMELAPSE PLOTS (Elapsed Time Per Mesh) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "            metric_ts = (df_plane.groupby(['timestamp', 'mesh', 'stack_group'])[metric].sum().reset_index())\n",
    "            metric_ts['elapsed_s'] = (metric_ts.groupby('mesh')['timestamp'].transform(lambda ts: (ts - ts.min()).dt.total_seconds()))\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for mesh_name in ['istio', 'linkerd']:\n",
    "                for comp in metric_ts.loc[metric_ts['mesh'] == mesh_name, 'stack_group'].unique():\n",
    "                    df_line = metric_ts[(metric_ts['mesh'] == mesh_name) & (metric_ts['stack_group'] == comp)]\n",
    "                    plt.plot(df_line['elapsed_s'], df_line[metric], marker='o', markersize=1, linewidth=1, label=f\"{mesh_name.capitalize()} - {comp}\")\n",
    "            plt.title(title.format(name=name, qps=unique_qps, payload=unique_payload, metric=metric.upper(), replicas=unique_replicas))\n",
    "            plt.xlabel(\"Time (seconds)\")\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.legend(ncol=2, frameon=False)\n",
    "            plt.grid(axis='both', linestyle='--', linewidth=0.5)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir,f\"{suffix}_timeline_{metric}_{unique_qps}_{unique_payload}_{unique_replicas}.png\"))\n",
    "            plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
