{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚è±Ô∏è Latency and Error Analysis Notebook\n",
    "\n",
    "This notebook analyzes **request latency** and **error latency** percentiles from Fortio JSON output files generated during HTTP load testing experiments.\n",
    "\n",
    "## üß™ Experiments Covered\n",
    "\n",
    "1. **01 - HTTP Max Throughput**\n",
    "    - Compares p50, p75, p90, and p99 latency and error latencies between Istio and Linkerd at max throughput.\n",
    "\n",
    "2. **02 - HTTP Constant Throughput**\n",
    "    - Runs at constant QPS values: 1, 1000, and 10000.\n",
    "    - Compares latency distributions per mesh across different traffic loads.\n",
    "\n",
    "3. **03 - HTTP Payload Variation**\n",
    "    - Uses fixed QPS (100) with varying payload sizes: 0, 1000, and 10000 bytes.\n",
    "    - Explores how latency changes with request payload size.\n",
    "\n",
    "## üìÅ Expected Input\n",
    "\n",
    "- JSON files under `../results/<experiment>/latencies_<mesh>_<qps>_<payload>_<timestamp>.json`\n",
    "- Structure:\n",
    "    - Fortio's `DurationHistogram` and `ErrorsDurationHistogram` blocks\n",
    "    - Extracted percentiles: **p50, p75, p90, p99**\n",
    "\n",
    "## üìâ Output\n",
    "\n",
    "- Line plots for latency and error latency percentiles (per experiment config).\n",
    "- Output PNGs are saved in:\n",
    "    - `../diagrams/<experiment>/experiment*_latency*.png`\n",
    "    - `../diagrams/<experiment>/experiment*_error_latency*.png`\n",
    "\n",
    "> üß™ **Benchmark Goal**: Compare service mesh behavior under varying load and payload profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_percentiles(data, error=False):\n",
    "    \"\"\"\n",
    "    Extract percentiles (p50, p75, p90, p99) from a Fortio JSON blob and convert to milliseconds.\n",
    "    \"\"\"\n",
    "    if error:\n",
    "        perc_list = data.get(\"ErrorsDurationHistogram\", {}).get(\"Percentiles\", [])\n",
    "    else:\n",
    "        perc_list = data.get(\"DurationHistogram\", {}).get(\"Percentiles\", [])\n",
    "    result = {}\n",
    "    for entry in perc_list:\n",
    "        p = entry.get(\"Percentile\")\n",
    "        if p in [50, 75, 90, 99]:\n",
    "            # Multiply by 1000 to convert seconds to milliseconds.\n",
    "            result[p] = entry.get(\"Value\") * 1000 if entry.get(\"Value\") is not None else None\n",
    "    return result\n",
    "\n",
    "def extract_params_from_filename(file_path):\n",
    "    \"\"\"\n",
    "    Parses a filename of the form:\n",
    "       latencies_<mesh>_<qps>_<payload>_<timestamp>.json\n",
    "    and returns (mesh, qps, payload).\n",
    "    \"\"\"\n",
    "    base = os.path.basename(file_path)\n",
    "    base = base[len(\"latencies_\"):]  # Remove prefix.\n",
    "    base = base.replace(\".json\", \"\")\n",
    "    parts = base.split(\"_\")\n",
    "    mesh = parts[0]\n",
    "    qps = int(parts[1])\n",
    "    payload = int(parts[2])\n",
    "    return mesh, qps, payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories for experiment 1.\n",
    "experiment_dir = os.path.join(\"..\", \"results\", \"01_http_max_throughput\")\n",
    "diagram_dir = os.path.join(\"..\", \"diagrams\", \"01_http_max_throughput\")\n",
    "os.makedirs(diagram_dir, exist_ok=True)\n",
    "\n",
    "# Locate all latency JSON files for experiment 1.\n",
    "latency_files = glob.glob(os.path.join(experiment_dir, \"latencies_*.json\"))\n",
    "\n",
    "# Dictionaries to store results per mesh.\n",
    "results_latency = {}  # For the normal latency percentiles.\n",
    "results_error = {}    # For error latency percentiles.\n",
    "\n",
    "for file in latency_files:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    mesh, qps, payload = extract_params_from_filename(file)\n",
    "    # (For experiment 1, qps and payload should be 0.)\n",
    "    results_latency[mesh] = extract_percentiles(data, error=False)\n",
    "    results_error[mesh]   = extract_percentiles(data, error=True)\n",
    "\n",
    "# Define x-axis labels.\n",
    "x_labels = [\"p50\", \"p75\", \"p90\", \"p99\"]\n",
    "\n",
    "# Plot latency percentiles.\n",
    "plt.figure(figsize=(15, 10))\n",
    "for mesh, percs in results_latency.items():\n",
    "    # Order values for 50, 75, 90, and 99\n",
    "    y_values = [percs.get(50), percs.get(75), percs.get(90), percs.get(99)]\n",
    "    plt.plot(x_labels, y_values, marker='o', label=mesh)\n",
    "plt.xlabel(\"Percentile\")\n",
    "plt.ylabel(\"Latency (ms)\")\n",
    "plt.title(\"Experiment 1: Latency Percentiles\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "latency_output_path = os.path.join(diagram_dir, \"global_latency_0.png\")\n",
    "plt.savefig(latency_output_path)\n",
    "plt.close()\n",
    "\n",
    "# Plot error latency percentiles.\n",
    "plt.figure(figsize=(15, 10))\n",
    "for mesh, percs in results_error.items():\n",
    "    y_values = [percs.get(50), percs.get(75), percs.get(90), percs.get(99)]\n",
    "    plt.plot(x_labels, y_values, marker='o', label=mesh)\n",
    "plt.xlabel(\"Percentile\")\n",
    "plt.ylabel(\"Error Latency (ms)\")\n",
    "plt.title(\"Experiment 1: Error Latency Percentiles\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "error_output_path = os.path.join(diagram_dir, \"global_latency_error_0.png\")\n",
    "plt.savefig(error_output_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Experiment 2 latency diagram for QPS 1 to ../diagrams/02_http_constant_throughput/global_latency_1.png\n",
      "Saved Experiment 2 latency diagram for QPS 1000 to ../diagrams/02_http_constant_throughput/global_latency_1000.png\n",
      "Saved Experiment 2 latency diagram for QPS 10000 to ../diagrams/02_http_constant_throughput/global_latency_10000.png\n",
      "Saved Experiment 2 latency diagram for QPS 100000 to ../diagrams/02_http_constant_throughput/global_latency_100000.png\n",
      "Saved Experiment 2 latency diagram for QPS 1000000 to ../diagrams/02_http_constant_throughput/global_latency_1000000.png\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Experiment 2: Latency and Error Percentiles for Throughputs 1, 1000, and 10000\n",
    "\n",
    "# Define directories for experiment 2.\n",
    "experiment_dir = os.path.join(\"..\", \"results\", \"02_http_constant_throughput\")\n",
    "diagram_dir = os.path.join(\"..\", \"diagrams\", \"02_http_constant_throughput\")\n",
    "os.makedirs(diagram_dir, exist_ok=True)\n",
    "\n",
    "# Locate all latency JSON files for experiment 2.\n",
    "latency_files = glob.glob(os.path.join(experiment_dir, \"latencies_*.json\"))\n",
    "\n",
    "# Group results by QPS.\n",
    "results_latency = {}  # structure: { qps: {mesh: {50:..., 75:..., ... } } }\n",
    "results_error = {}    # similar structure for error histogram.\n",
    "\n",
    "for file in latency_files:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    mesh, qps, payload = extract_params_from_filename(file)\n",
    "    # (For experiment 2, payload is expected to be 0.)\n",
    "    if qps not in results_latency:\n",
    "        results_latency[qps] = {}\n",
    "        results_error[qps] = {}\n",
    "    results_latency[qps][mesh] = extract_percentiles(data, error=False)\n",
    "    results_error[qps][mesh]   = extract_percentiles(data, error=True)\n",
    "\n",
    "x_labels = [\"p50\", \"p75\", \"p90\", \"p99\"]\n",
    "\n",
    "# For each QPS value (1, 1000, 10000), generate latency and error plots.\n",
    "for qps_val in sorted(results_latency.keys()):\n",
    "    # Latency Plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for mesh, percs in results_latency[qps_val].items():\n",
    "        y_values = [percs.get(50), percs.get(75), percs.get(90), percs.get(99)]\n",
    "        plt.plot(x_labels, y_values, marker='o', label=mesh)\n",
    "    plt.xlabel(\"Percentile\")\n",
    "    plt.ylabel(\"Latency (ms)\")\n",
    "    plt.title(f\"Experiment 2: Latency Percentiles at QPS = {qps_val}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    latency_outfile = os.path.join(diagram_dir, f\"global_latency_{qps_val}.png\")\n",
    "    plt.savefig(latency_outfile)\n",
    "    plt.close()\n",
    "    print(\"Saved Experiment 2 latency diagram for QPS\", qps_val, \"to\", latency_outfile)\n",
    "    \n",
    "    # Error Latency Plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for mesh, percs in results_error[qps_val].items():\n",
    "        y_values = [percs.get(50), percs.get(75), percs.get(90), percs.get(99)]\n",
    "        plt.plot(x_labels, y_values, marker='o', label=mesh)\n",
    "    plt.xlabel(\"Percentile\")\n",
    "    plt.ylabel(\"Error Latency (ms)\")\n",
    "    plt.title(f\"Experiment 2: Error Latency Percentiles at QPS = {qps_val}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    error_outfile = os.path.join(diagram_dir, f\"global_latency_error_{qps_val}.png\")\n",
    "    plt.savefig(error_outfile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories for experiment 3.\n",
    "experiment_dir = os.path.join(\"..\", \"results\", \"03_http_payload\")\n",
    "diagram_dir = os.path.join(\"..\", \"diagrams\", \"03_http_payload\")\n",
    "os.makedirs(diagram_dir, exist_ok=True)\n",
    "\n",
    "# Locate all latency JSON files for experiment 3.\n",
    "latency_files = glob.glob(os.path.join(experiment_dir, \"latencies_*.json\"))\n",
    "\n",
    "# Group results by payload (qps is expected to be 100 in this experiment).\n",
    "results_latency = {}  # structure: { payload: {mesh: {50:..., 75:..., ... } } }\n",
    "results_error = {}    # similar grouping for error histograms.\n",
    "\n",
    "for file in latency_files:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    mesh, qps, payload = extract_params_from_filename(file)\n",
    "    if payload not in results_latency:\n",
    "        results_latency[payload] = {}\n",
    "        results_error[payload] = {}\n",
    "    results_latency[payload][mesh] = extract_percentiles(data, error=False)\n",
    "    results_error[payload][mesh]   = extract_percentiles(data, error=True)\n",
    "\n",
    "x_labels = [\"p50\", \"p75\", \"p90\", \"p99\"]\n",
    "\n",
    "# For each payload value, generate latency and error plots.\n",
    "for payload_val in sorted(results_latency.keys()):\n",
    "    # Latency Plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for mesh, percs in results_latency[payload_val].items():\n",
    "        y_values = [percs.get(50), percs.get(75), percs.get(90), percs.get(99)]\n",
    "        plt.plot(x_labels, y_values, marker='o', label=mesh)\n",
    "    plt.xlabel(\"Percentile\")\n",
    "    plt.ylabel(\"Latency (ms)\")\n",
    "    plt.title(f\"Experiment 3: Latency Percentiles (Throughput 100, Payload = {payload_val})\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    latency_outfile = os.path.join(diagram_dir, f\"global_latency_100_{payload_val}.png\")\n",
    "    plt.savefig(latency_outfile)\n",
    "    plt.close()\n",
    "    \n",
    "    # Error Latency Plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for mesh, percs in results_error[payload_val].items():\n",
    "        y_values = [percs.get(50), percs.get(75), percs.get(90), percs.get(99)]\n",
    "        plt.plot(x_labels, y_values, marker='o', label=mesh)\n",
    "    plt.xlabel(\"Percentile\")\n",
    "    plt.ylabel(\"Error Latency (ms)\")\n",
    "    plt.title(f\"Experiment 3: Error Latency Percentiles (Throughput 100, Payload = {payload_val})\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    error_outfile = os.path.join(diagram_dir, f\"global_latency_error_100_{payload_val}.png\")\n",
    "    plt.savefig(error_outfile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories for experiment 4.\n",
    "grpc_experiment_dir = os.path.join(\"..\", \"results\", \"04_grpc_max_throughput\")\n",
    "grpc_diagram_dir = os.path.join(\"..\", \"diagrams\", \"04_grpc_max_throughput\")\n",
    "os.makedirs(grpc_diagram_dir, exist_ok=True)\n",
    "\n",
    "# Locate all latency JSON files for experiment 4.\n",
    "grpc_latency_files = glob.glob(os.path.join(grpc_experiment_dir, \"latencies_*.json\"))\n",
    "\n",
    "# Group results by payload (or any parameter extracted from the filename).\n",
    "# The structure is: { payload: {mesh: {50: value, 75: value, 90: value, 99: value} } }\n",
    "results_latency_grpc = {}\n",
    "results_error_grpc = {}\n",
    "\n",
    "for file in grpc_latency_files:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    # This function is assumed to extract the mesh name, qps, and payload information from the filename.\n",
    "    mesh, qps, payload = extract_params_from_filename(file)\n",
    "    if payload not in results_latency_grpc:\n",
    "        results_latency_grpc[payload] = {}\n",
    "        results_error_grpc[payload] = {}\n",
    "    # extract_percentiles should parse the JSON and return a dictionary mapping percentile to value.\n",
    "    results_latency_grpc[payload][mesh] = extract_percentiles(data, error=False)\n",
    "    results_error_grpc[payload][mesh] = extract_percentiles(data, error=True)\n",
    "\n",
    "x_labels = [\"p50\", \"p75\", \"p90\", \"p99\"]\n",
    "\n",
    "# For each payload value, generate latency and error plots for GRPC.\n",
    "for payload_val in sorted(results_latency_grpc.keys()):\n",
    "    # ---------------------\n",
    "    # GRPC Latency Plot\n",
    "    # ---------------------\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for mesh, percs in results_latency_grpc[payload_val].items():\n",
    "        # The keys 50, 75, 90, and 99 should be available in the dictionary returned by extract_percentiles.\n",
    "        y_values = [percs.get(50), percs.get(75), percs.get(90), percs.get(99)]\n",
    "        plt.plot(x_labels, y_values, marker='o', label=mesh)\n",
    "    plt.xlabel(\"Percentile\")\n",
    "    plt.ylabel(\"Latency (ms)\")\n",
    "    plt.title(f\"GRPC: Latency Percentiles (Throughput 0, Payload = {payload_val})\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    latency_outfile = os.path.join(grpc_diagram_dir, f\"global_latency_0_{payload_val}.png\")\n",
    "    plt.savefig(latency_outfile)\n",
    "    plt.close()\n",
    "    \n",
    "    # ------------------------------\n",
    "    # GRPC Error Latency Plot\n",
    "    # ------------------------------\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for mesh, percs in results_error_grpc[payload_val].items():\n",
    "        y_values = [percs.get(50), percs.get(75), percs.get(90), percs.get(99)]\n",
    "        plt.plot(x_labels, y_values, marker='o', label=mesh)\n",
    "    plt.xlabel(\"Percentile\")\n",
    "    plt.ylabel(\"Error Latency (ms)\")\n",
    "    plt.title(f\"GRPC: Error Latency Percentiles (Throughput 0, Payload = {payload_val})\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    error_outfile = os.path.join(grpc_diagram_dir, f\"global_latency_error_0_{payload_val}.png\")\n",
    "    plt.savefig(error_outfile)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
